{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3f53cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ebbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"your-hugging-token-face-token-api\"  # Use your token\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"your-langsmith-token-api\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed29876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAQ dataset\n",
    "with open(\"Ecommerce_FAQ_Chatbot_dataset.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "documents = []\n",
    "for entry in data[\"questions\"]:\n",
    "    q = entry[\"question\"].strip()\n",
    "    a = entry[\"answer\"].strip()\n",
    "    documents.append(f\"Q: {q}\\nA: {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9328f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Document List (first 3 docs shown):\n",
      "Q: How can I create an account?\n",
      "A: To create an account, click on the 'Sign Up' button on the top right corner of our website and follow the instructions to complete the registration process.\n",
      "Q: What payment methods do you accept?\n",
      "A: We accept major credit cards, debit cards, and PayPal as payment methods for online orders.\n",
      "Q: How can I track my order?\n",
      "A: You can track your order by logging into your account and navigating to the 'Order History' section. There, you will find the tracking information for your shipment.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProcessed Document List (first 3 docs shown):\")\n",
    "for d in documents[:3]:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615a7fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103860/412152783.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0a7381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization Output for Documents (showing input_ids and attention_mask for first doc):\n",
      "Input IDs: tensor([  101,  1053,  1024,  2129,  2064,  1045,  3443,  2019,  4070,  1029,\n",
      "         1037,  1024,  2000,  3443,  2019,  4070,  1010, 11562,  2006,  1996,\n",
      "         1005,  3696,  2039,  1005,  6462,  2006,  1996,  2327,  2157,  3420,\n",
      "         1997,  2256,  4037,  1998,  3582,  1996,  8128,  2000,  3143,  1996,\n",
      "         8819,  2832,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize documents for debugging output\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "tokens = tokenizer(documents, padding=True, truncation=True, return_tensors='pt')\n",
    "print(\"\\nTokenization Output for Documents (showing input_ids and attention_mask for first doc):\")\n",
    "print(\"Input IDs:\", tokens[\"input_ids\"][0])\n",
    "print(\"Attention Mask:\", tokens[\"attention_mask\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a20a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embeddings Output:\n",
      "Document 1 embedding shape: 384\n",
      "Document 2 embedding shape: 384\n",
      "Document 3 embedding shape: 384\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for documents\n",
    "raw_embeddings = embedding_model.embed_documents(documents)\n",
    "print(\"\\nEmbeddings Output:\")\n",
    "for i, emb in enumerate(raw_embeddings[:3]):\n",
    "    print(f\"Document {i+1} embedding shape: {len(emb)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd52ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize embeddings to ensure cosine similarity behavior.\n",
    "def normalize(emb):\n",
    "    arr = np.array(emb)\n",
    "    norm = np.linalg.norm(arr)\n",
    "    return (arr / norm).tolist() if norm != 0 else emb\n",
    "\n",
    "normalized_embeddings = [normalize(emb) for emb in raw_embeddings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2008bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine documents with their normalized embeddings as (document, embedding) pairs.\n",
    "doc_embeddings = list(zip(documents, normalized_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e3cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_embeddings(doc_embeddings, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad1c195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "040369e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103860/3634644841.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c94f4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = LangChainTracer(project_name=\"agent-chatbot\")\n",
    "callback_manager = CallbackManager([tracer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "064c5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_similarity(distance):\n",
    "    return 1 / (1 + distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "069cf662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity search results (with converted similarity scores):\n",
      "\n",
      "[Document 1]:\n",
      "Q: How can I create an account?\n",
      "A: To create an account, click on the 'Sign Up' button on the top right corner of our website and follow the instructions to complete the registration process.\n",
      "Distance Score: 0.293128192425, Converted Similarity: 0.773318529129\n",
      "\n",
      "[Document 2]:\n",
      "Q: Can I order without creating an account?\n",
      "A: Yes, you can place an order as a guest without creating an account. However, creating an account offers benefits such as order tracking and easier future purchases.\n",
      "Distance Score: 1.007702350616, Converted Similarity: 0.498081803322\n",
      "\n",
      "[Document 3]:\n",
      "Q: Do you have a loyalty program?\n",
      "A: Yes, we have a loyalty program where you can earn points for every purchase. These points can be redeemed for discounts on future orders. Please visit our website to learn more and join the program.\n",
      "Distance Score: 1.459196686745, Converted Similarity: 0.406636863947\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"How can I create an account?\"\n",
    "results = vectorstore.similarity_search_with_score(sample_query, k=3)\n",
    "print(\"\\nSimilarity search results (with converted similarity scores):\")\n",
    "for i, (doc, score) in enumerate(results, start=1):\n",
    "    similarity = distance_to_similarity(score)\n",
    "    print(f\"\\n[Document {i}]:\\n{doc.page_content}\")\n",
    "    print(f\"Distance Score: {score:.12f}, Converted Similarity: {similarity:.12f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc15f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103860/2412962749.py:2: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n",
      "/tmp/ipykernel_103860/2412962749.py:2: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = HuggingFaceHub(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM \n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-small\",\n",
    "    model_kwargs={\"max_new_tokens\": 150, \"temperature\": 0.7},\n",
    "    callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef7d30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Conversational Retrieval Chain using the LLM and retriever.\n",
    "faq_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    callback_manager=callback_manager,\n",
    "    return_source_documents=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9be1e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAQ Chatbot is ready. Type your questions (or type 'exit' to quit):\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Is there a mobile app available for placing orders and tracking shipments?\n",
      "Assistant: Yes, there is a mobile app available for placing orders and tracking shipments.\n",
      "Human: quit \n",
      "Assistant: Helpful\n",
      "Human: Whatâ€™s the best way to reach your customer service if I have an issue with my order?\n",
      "Assistant: Customer service is a priority.\n",
      "Follow Up Input: Can I update or change my payment method after placing an order?\n",
      "Standalone question:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/astechware/Projects/NLP&LLM basics/.conda/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Q: Can I change or cancel an item in my order?\n",
      "A: If you need to change or cancel an item in your order, please contact our customer support team as soon as possible. We will assist you with the necessary steps.\n",
      "\n",
      "Q: Can I change my shipping address after placing an order?\n",
      "A: If you need to change your shipping address, please contact our customer support team as soon as possible. We will do our best to update the address if the order has not been shipped yet.\n",
      "\n",
      "Q: What payment methods do you accept?\n",
      "A: We accept major credit cards, debit cards, and PayPal as payment methods for online orders.\n",
      "\n",
      "Question: Is there a way to change my payment method after placing an order?\n",
      "Helpful Answer:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/astechware/Projects/NLP&LLM basics/.conda/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: We accept major credit cards, debit cards, and PayPal as payment methods for online orders.\n",
      "\n",
      "[Source Document 1]:\n",
      "Q: Can I change or cancel an item in my order?\n",
      "A: If you need to change or cancel an item in your order, please contact our customer support team as soon as possible. We will assist you with the necessary steps.\n",
      "Distance Score: 0.856783986092, Converted Similarity: 0.538565635681\n",
      "\n",
      "[Source Document 2]:\n",
      "Q: Can I change my shipping address after placing an order?\n",
      "A: If you need to change your shipping address, please contact our customer support team as soon as possible. We will do our best to update the address if the order has not been shipped yet.\n",
      "Distance Score: 0.944577336311, Converted Similarity: 0.514250576496\n",
      "\n",
      "[Source Document 3]:\n",
      "Q: What payment methods do you accept?\n",
      "A: We accept major credit cards, debit cards, and PayPal as payment methods for online orders.\n",
      "Distance Score: 1.167297601700, Converted Similarity: 0.461404114962\n",
      "Exiting the chatbot session.\n"
     ]
    }
   ],
   "source": [
    "# Chatbot loop\n",
    "print(\"FAQ Chatbot is ready. Type your questions (or type 'exit' to quit):\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting the chatbot session.\")\n",
    "        break\n",
    "\n",
    "    response = faq_chain({\"question\": user_input})\n",
    "    print(\"Bot:\", response[\"answer\"])\n",
    "    \n",
    "    # Retrieve top-3 documents with scores using the query,\n",
    "    # showing converted similarity for display.\n",
    "    results = vectorstore.similarity_search_with_score(user_input, k=3)\n",
    "    for i, (doc, score) in enumerate(results, start=1):\n",
    "        similarity = distance_to_similarity(score)\n",
    "        print(f\"\\n[Source Document {i}]:\\n{doc.page_content}\")\n",
    "        print(f\"Distance Score: {score:.12f}, Converted Similarity: {similarity:.12f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
